{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from scipy.stats import ks_2samp\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res = pd.read_csv('database/X_train_res.csv').drop(columns=['Unnamed: 0'])\n",
    "y_train_res = pd.read_csv('database/y_train_res.csv').drop(columns=['Unnamed: 0'])\n",
    "X_val = pd.read_csv('database/X_val.csv').drop(columns=['INDEX'])\n",
    "y_val = pd.read_csv('database/y_val.csv', names=['INDEX', 'IND_BOM_1_1']).drop(columns=['INDEX'])\n",
    "X_test = pd.read_csv('database/X_test.csv').drop(columns=['INDEX'])\n",
    "y_test = pd.read_csv('database/y_test.csv', names=['INDEX', 'IND_BOM_1_1']).drop(columns=['INDEX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(list(X_train_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Treinando MLPs</h2>\n",
    "<p>Para o treino de MLPs foram testadas diversas formas de otimizar hiperparâmetros como: learning rate, algoritmo de otimização, número de camadas escondidas, etc. A estimativa do learning rate e do número de camadas escondidas foi feita automaticamente a partir do conjunto de validação.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>O MLP Básico</h3>\n",
    "<p>O MLP é montado com base na biblioteca Keras e segue uma estrutura básica:</p>\n",
    "<ul>\n",
    "    <li>O MLP em si é uma classe Sequential e nela serão adicionadas as camadas de entrada, saída e internas.</li>\n",
    "    <li>As camadas são uma classe Dense. Passamos para o construtor dessa classe o número de nodes, a função de ativação e, no caso de ser a primeira camada, a dimensão da entrada.</li>\n",
    "    <li>Antes de treinar o MLP, devemos compilar o mesmo e setar parâmetros como a função de otimização, algumas métricas opcionais como 'accuracy' e a função de perda, que retorna uma métrica para avaliarmos o MLP</li>\n",
    "    <li>Para treinarmos o modelo utilizaremos a função fit que recebe como parâmetros X sendo as amostras para treinamento, y sendo as classes de cada amostra, batch_size sendo o comprimento do batch utilizado no treinamento, o número de epochs sendo quantas vezes iremos dar entrada com o dataset para o treinamento, validation_data sendo os dados utilizados para validação e callbacks para pararmos o treinamento com certas condições.</li>\n",
    "</ul>\n",
    "<p>Para a primeira fase, procuraremos funções de ativação, número de nós na camada de entrada e função de otimização que melhorem o acerto no conjunto de validação</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Estimando Hiperparâmetros</h3>\n",
    "<ul>\n",
    "    <li>Função de Ativação</li>\n",
    "    <li>Função de Otimização</li>\n",
    "    <li>Camadas escondidas</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Função de Ativação nas Camadas de Entrada</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 10s 32us/step - loss: 0.6387 - acc: 0.6349 - val_loss: 0.6529 - val_acc: 0.6093\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 9s 30us/step - loss: 0.6227 - acc: 0.6523 - val_loss: 0.6222 - val_acc: 0.6409\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 9s 30us/step - loss: 0.6134 - acc: 0.6619 - val_loss: 0.6635 - val_acc: 0.6054\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 9s 29us/step - loss: 0.6033 - acc: 0.6715 - val_loss: 0.6181 - val_acc: 0.6520\n",
      "Epoch 5/100000\n",
      "307646/307646 [==============================] - 9s 29us/step - loss: 0.5942 - acc: 0.6780 - val_loss: 0.6286 - val_acc: 0.6452\n",
      "Epoch 6/100000\n",
      "307646/307646 [==============================] - 9s 30us/step - loss: 0.5862 - acc: 0.6830 - val_loss: 0.6384 - val_acc: 0.6315\n",
      "Epoch 7/100000\n",
      "307646/307646 [==============================] - 9s 29us/step - loss: 0.5804 - acc: 0.6865 - val_loss: 0.6222 - val_acc: 0.6503\n"
     ]
    }
   ],
   "source": [
    "mlp = Sequential()\n",
    "mlp.add(Dense(20, activation='tanh', input_dim=input_dim)) # Camada de entrada\n",
    "mlp.add(Dense(1, activation='sigmoid')) # Camada de saída\n",
    "mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = mlp.fit(X_train_res, y_train_res, batch_size=64, epochs=100000, \n",
    "        callbacks=[EarlyStopping(patience=3)], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Média de Validação: 0.64\n"
     ]
    }
   ],
   "source": [
    "print(\"Perda Média de Validação: %.2f\"%(np.mean(history.history['val_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 10s 32us/step - loss: 0.6378 - acc: 0.6367 - val_loss: 0.6471 - val_acc: 0.6133\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 9s 30us/step - loss: 0.6207 - acc: 0.6546 - val_loss: 0.6279 - val_acc: 0.6369\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 9s 30us/step - loss: 0.6096 - acc: 0.6645 - val_loss: 0.6541 - val_acc: 0.6150\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 9s 31us/step - loss: 0.5953 - acc: 0.6774 - val_loss: 0.6332 - val_acc: 0.6355\n",
      "Epoch 5/100000\n",
      "307646/307646 [==============================] - 9s 30us/step - loss: 0.5823 - acc: 0.6854 - val_loss: 0.6117 - val_acc: 0.6581\n",
      "Epoch 6/100000\n",
      "307646/307646 [==============================] - 9s 31us/step - loss: 0.5729 - acc: 0.6909 - val_loss: 0.6223 - val_acc: 0.6508\n",
      "Epoch 7/100000\n",
      "307646/307646 [==============================] - 9s 30us/step - loss: 0.5663 - acc: 0.6951 - val_loss: 0.6229 - val_acc: 0.6491\n",
      "Epoch 8/100000\n",
      "307646/307646 [==============================] - 10s 31us/step - loss: 0.5614 - acc: 0.6983 - val_loss: 0.6199 - val_acc: 0.6536\n"
     ]
    }
   ],
   "source": [
    "mlp = Sequential()\n",
    "mlp.add(Dense(30, activation='tanh', input_dim=input_dim)) # Camada de entrada\n",
    "mlp.add(Dense(1, activation='sigmoid')) # Camada de saída\n",
    "mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = mlp.fit(X_train_res, y_train_res, batch_size=64, epochs=100000, \n",
    "        callbacks=[EarlyStopping(patience=3)], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Média de Validação: 0.63\n"
     ]
    }
   ],
   "source": [
    "print(\"Perda Média de Validação: %.2f\"%(np.mean(history.history['val_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 10s 34us/step - loss: 0.6377 - acc: 0.6370 - val_loss: 0.6409 - val_acc: 0.6227\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 10s 32us/step - loss: 0.6211 - acc: 0.6537 - val_loss: 0.6057 - val_acc: 0.6603\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 11s 34us/step - loss: 0.6104 - acc: 0.6652 - val_loss: 0.6192 - val_acc: 0.6449\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 10s 34us/step - loss: 0.5976 - acc: 0.6770 - val_loss: 0.6186 - val_acc: 0.6513\n",
      "Epoch 5/100000\n",
      "307646/307646 [==============================] - 10s 33us/step - loss: 0.5832 - acc: 0.6875 - val_loss: 0.6590 - val_acc: 0.6079\n"
     ]
    }
   ],
   "source": [
    "mlp = Sequential()\n",
    "mlp.add(Dense(50, activation='tanh', input_dim=input_dim)) # Camada de entrada\n",
    "mlp.add(Dense(1, activation='sigmoid')) # Camada de saída\n",
    "mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = mlp.fit(X_train_res, y_train_res, batch_size=64, epochs=100000, \n",
    "        callbacks=[EarlyStopping(patience=3)], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Média de Validação: 0.63\n"
     ]
    }
   ],
   "source": [
    "print(\"Perda Média de Validação: %.2f\"%(np.mean(history.history['val_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 13s 41us/step - loss: 0.6361 - acc: 0.6367 - val_loss: 0.6351 - val_acc: 0.6256\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 12s 39us/step - loss: 0.6185 - acc: 0.6568 - val_loss: 0.6325 - val_acc: 0.6301\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 12s 38us/step - loss: 0.6070 - acc: 0.6685 - val_loss: 0.6712 - val_acc: 0.5963\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 12s 38us/step - loss: 0.5938 - acc: 0.6805 - val_loss: 0.6317 - val_acc: 0.6400\n",
      "Epoch 5/100000\n",
      "307646/307646 [==============================] - 12s 38us/step - loss: 0.5776 - acc: 0.6920 - val_loss: 0.6151 - val_acc: 0.6576\n",
      "Epoch 6/100000\n",
      "307646/307646 [==============================] - 12s 39us/step - loss: 0.5630 - acc: 0.7003 - val_loss: 0.6172 - val_acc: 0.6556\n",
      "Epoch 7/100000\n",
      "307646/307646 [==============================] - 12s 38us/step - loss: 0.5523 - acc: 0.7069 - val_loss: 0.6481 - val_acc: 0.6312\n",
      "Epoch 8/100000\n",
      "307646/307646 [==============================] - 13s 42us/step - loss: 0.5444 - acc: 0.7117 - val_loss: 0.6496 - val_acc: 0.6254\n"
     ]
    }
   ],
   "source": [
    "mlp = Sequential()\n",
    "mlp.add(Dense(100, activation='tanh', input_dim=input_dim)) # Camada de entrada\n",
    "mlp.add(Dense(1, activation='sigmoid')) # Camada de saída\n",
    "mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = mlp.fit(X_train_res, y_train_res, batch_size=64, epochs=100000, \n",
    "        callbacks=[EarlyStopping(patience=3)], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Média de Validação: 0.64\n"
     ]
    }
   ],
   "source": [
    "print(\"Perda Média de Validação: %.2f\"%(np.mean(history.history['val_loss'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Pela configuração atual notamos que o número de nós na camada de entrada não influenciou muito na perda sobre o conjunto de validação, porém 30 obteve um valor mais baixo de 0.63. Manteremos esse valor.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 14s 44us/step - loss: 0.6413 - acc: 0.6330 - val_loss: 0.6264 - val_acc: 0.6404\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 12s 39us/step - loss: 0.6276 - acc: 0.6466 - val_loss: 0.6303 - val_acc: 0.6302\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 14s 45us/step - loss: 0.6180 - acc: 0.6571 - val_loss: 0.6813 - val_acc: 0.5801\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 14s 46us/step - loss: 0.6083 - acc: 0.6668 - val_loss: 0.6276 - val_acc: 0.6396\n"
     ]
    }
   ],
   "source": [
    "mlp = Sequential()\n",
    "mlp.add(Dense(100, activation='sigmoid', input_dim=input_dim)) # Camada de entrada\n",
    "mlp.add(Dense(1, activation='sigmoid')) # Camada de saída\n",
    "mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = mlp.fit(X_train_res, y_train_res, batch_size=64, epochs=100000, \n",
    "        callbacks=[EarlyStopping(patience=3)], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Média de Validação: 0.64\n"
     ]
    }
   ],
   "source": [
    "print(\"Perda Média de Validação: %.2f\"%(np.mean(history.history['val_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 14s 46us/step - loss: 0.6314 - acc: 0.6433 - val_loss: 0.6429 - val_acc: 0.6159\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 12s 40us/step - loss: 0.6119 - acc: 0.6648 - val_loss: 0.6307 - val_acc: 0.6332\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 12s 38us/step - loss: 0.5967 - acc: 0.6793 - val_loss: 0.6360 - val_acc: 0.6288\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 12s 39us/step - loss: 0.5821 - acc: 0.6900 - val_loss: 0.6298 - val_acc: 0.6393\n",
      "Epoch 5/100000\n",
      "307646/307646 [==============================] - 14s 44us/step - loss: 0.5690 - acc: 0.6982 - val_loss: 0.6194 - val_acc: 0.6569\n",
      "Epoch 6/100000\n",
      "307646/307646 [==============================] - 12s 38us/step - loss: 0.5587 - acc: 0.7043 - val_loss: 0.6146 - val_acc: 0.6647\n",
      "Epoch 7/100000\n",
      "307646/307646 [==============================] - 12s 40us/step - loss: 0.5507 - acc: 0.7089 - val_loss: 0.6228 - val_acc: 0.6480\n",
      "Epoch 8/100000\n",
      "307646/307646 [==============================] - 13s 43us/step - loss: 0.5444 - acc: 0.7121 - val_loss: 0.6492 - val_acc: 0.6293\n",
      "Epoch 9/100000\n",
      "307646/307646 [==============================] - 13s 42us/step - loss: 0.5399 - acc: 0.7152 - val_loss: 0.6342 - val_acc: 0.6400\n"
     ]
    }
   ],
   "source": [
    "mlp = Sequential()\n",
    "mlp.add(Dense(100, activation='relu', input_dim=input_dim)) # Camada de entrada\n",
    "mlp.add(Dense(1, activation='sigmoid')) # Camada de saída\n",
    "mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = mlp.fit(X_train_res, y_train_res, batch_size=64, epochs=100000, \n",
    "        callbacks=[EarlyStopping(patience=3)], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Média de Validação: 0.63\n"
     ]
    }
   ],
   "source": [
    "print(\"Perda Média de Validação: %.2f\"%(np.mean(history.history['val_loss'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Modificando as funções de ativação na camada de entrada também não variou muito a perda média. Testamos então na camada de saída.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 14s 45us/step - loss: 6.3356 - acc: 0.5250 - val_loss: 10.5645 - val_acc: 0.3446\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 13s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 10.5645 - val_acc: 0.3446\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 13s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 10.5645 - val_acc: 0.3446\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 13s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 10.5645 - val_acc: 0.3446\n"
     ]
    }
   ],
   "source": [
    "mlp = Sequential()\n",
    "mlp.add(Dense(100, activation='sigmoid', input_dim=input_dim)) # Camada de entrada\n",
    "mlp.add(Dense(1, activation='relu')) # Camada de saída\n",
    "mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = mlp.fit(X_train_res, y_train_res, batch_size=64, epochs=100000, \n",
    "        callbacks=[EarlyStopping(patience=3)], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Média de Validação: 10.56\n"
     ]
    }
   ],
   "source": [
    "print(\"Perda Média de Validação: %.2f\"%(np.mean(history.history['val_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 12s 41us/step - loss: 0.6493 - acc: 0.6261 - val_loss: 0.6383 - val_acc: 0.6350\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 12s 39us/step - loss: 0.6314 - acc: 0.6451 - val_loss: 0.6723 - val_acc: 0.5946\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 12s 40us/step - loss: 0.6187 - acc: 0.6563 - val_loss: 0.6526 - val_acc: 0.6146\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 14s 45us/step - loss: 0.6076 - acc: 0.6672 - val_loss: 0.6352 - val_acc: 0.6330\n",
      "Epoch 5/100000\n",
      "307646/307646 [==============================] - 13s 43us/step - loss: 0.5951 - acc: 0.6769 - val_loss: 0.6264 - val_acc: 0.6447\n",
      "Epoch 6/100000\n",
      "307646/307646 [==============================] - 12s 40us/step - loss: 0.5806 - acc: 0.6873 - val_loss: 0.6421 - val_acc: 0.6383\n",
      "Epoch 7/100000\n",
      "307646/307646 [==============================] - 13s 41us/step - loss: 0.5835 - acc: 0.6874 - val_loss: 0.6258 - val_acc: 0.6448\n",
      "Epoch 8/100000\n",
      "307646/307646 [==============================] - 14s 47us/step - loss: 0.5848 - acc: 0.6859 - val_loss: 0.6137 - val_acc: 0.6572\n",
      "Epoch 9/100000\n",
      "307646/307646 [==============================] - 14s 46us/step - loss: 0.5710 - acc: 0.6939 - val_loss: 0.6325 - val_acc: 0.6381\n",
      "Epoch 10/100000\n",
      "307646/307646 [==============================] - 14s 45us/step - loss: 0.5557 - acc: 0.7016 - val_loss: 0.6129 - val_acc: 0.6583\n",
      "Epoch 11/100000\n",
      "307646/307646 [==============================] - 15s 48us/step - loss: 0.5474 - acc: 0.7020 - val_loss: 0.6415 - val_acc: 0.6631\n",
      "Epoch 12/100000\n",
      "307646/307646 [==============================] - 13s 41us/step - loss: 0.5446 - acc: 0.7016 - val_loss: 0.6201 - val_acc: 0.6535\n",
      "Epoch 13/100000\n",
      "307646/307646 [==============================] - 16s 53us/step - loss: 0.5374 - acc: 0.7018 - val_loss: 0.6783 - val_acc: 0.6405\n"
     ]
    }
   ],
   "source": [
    "mlp = Sequential()\n",
    "mlp.add(Dense(100, activation='sigmoid', input_dim=input_dim)) # Camada de entrada\n",
    "mlp.add(Dense(1, activation='tanh')) # Camada de saída\n",
    "mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = mlp.fit(X_train_res, y_train_res, batch_size=64, epochs=100000, \n",
    "        callbacks=[EarlyStopping(patience=3)], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Média de Validação: 0.64\n"
     ]
    }
   ],
   "source": [
    "print(\"Perda Média de Validação: %.2f\"%(np.mean(history.history['val_loss'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Notamos que utilizando ReLU como função de ativação na camada de saída não gera bons resultados, mas na camada de entrada obteve a menor perda. Por fim optamos por manter ReLU na camada de entrada e Sigmoid na de saída.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Algoritmo de Otimização</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 14s 45us/step - loss: 0.6602 - acc: 0.6067 - val_loss: 0.6258 - val_acc: 0.6511\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 13s 43us/step - loss: 0.6475 - acc: 0.6272 - val_loss: 0.7155 - val_acc: 0.5736\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 11s 37us/step - loss: 7.1530 - acc: 0.5144 - val_loss: 5.4931 - val_acc: 0.6554\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 11s 37us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.4931 - val_acc: 0.6554\n"
     ]
    }
   ],
   "source": [
    "mlp = Sequential()\n",
    "mlp.add(Dense(100, activation='sigmoid', input_dim=input_dim)) # Camada de entrada\n",
    "mlp.add(Dense(1, activation='tanh')) # Camada de saída\n",
    "mlp.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = mlp.fit(X_train_res, y_train_res, batch_size=64, epochs=100000, \n",
    "        callbacks=[EarlyStopping(patience=3)], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Média de Validação: 3.08\n"
     ]
    }
   ],
   "source": [
    "print(\"Perda Média de Validação: %.2f\"%(np.mean(history.history['val_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 14s 45us/step - loss: 0.6479 - acc: 0.6272 - val_loss: 0.7031 - val_acc: 0.5805\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 15s 47us/step - loss: 0.6430 - acc: 0.6335 - val_loss: 0.6784 - val_acc: 0.6076\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 15s 47us/step - loss: 0.6389 - acc: 0.6382 - val_loss: 0.6796 - val_acc: 0.5912\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 14s 45us/step - loss: 0.6309 - acc: 0.6456 - val_loss: 0.6575 - val_acc: 0.6104\n",
      "Epoch 5/100000\n",
      "307646/307646 [==============================] - 12s 40us/step - loss: 0.6270 - acc: 0.6498 - val_loss: 0.6443 - val_acc: 0.6222\n",
      "Epoch 6/100000\n",
      "307646/307646 [==============================] - 13s 42us/step - loss: 0.6217 - acc: 0.6541 - val_loss: 0.6298 - val_acc: 0.6391\n",
      "Epoch 7/100000\n",
      "307646/307646 [==============================] - 13s 43us/step - loss: 0.6184 - acc: 0.6572 - val_loss: 0.6240 - val_acc: 0.6424\n",
      "Epoch 8/100000\n",
      "307646/307646 [==============================] - 13s 42us/step - loss: 0.6138 - acc: 0.6622 - val_loss: 0.6620 - val_acc: 0.6111\n",
      "Epoch 9/100000\n",
      "307646/307646 [==============================] - 13s 42us/step - loss: 0.6063 - acc: 0.6696 - val_loss: 0.6250 - val_acc: 0.6408\n",
      "Epoch 10/100000\n",
      "307646/307646 [==============================] - 14s 46us/step - loss: 0.5966 - acc: 0.6771 - val_loss: 0.6336 - val_acc: 0.6367\n"
     ]
    }
   ],
   "source": [
    "mlp = Sequential()\n",
    "mlp.add(Dense(100, activation='sigmoid', input_dim=input_dim)) # Camada de entrada\n",
    "mlp.add(Dense(1, activation='tanh')) # Camada de saída\n",
    "mlp.compile(optimizer='adamax', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = mlp.fit(X_train_res, y_train_res, batch_size=64, epochs=100000, \n",
    "        callbacks=[EarlyStopping(patience=3)], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perda Média de Validação: 0.65\n"
     ]
    }
   ],
   "source": [
    "print(\"Perda Média de Validação: %.2f\"%(np.mean(history.history['val_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 11s 37us/step - loss: 0.6451 - acc: 0.6288 - val_loss: 0.6404 - val_acc: 0.6250\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 11s 35us/step - loss: 0.6303 - acc: 0.6456 - val_loss: 0.6036 - val_acc: 0.6661\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 11s 35us/step - loss: 0.6219 - acc: 0.6531 - val_loss: 0.6252 - val_acc: 0.6357\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 11s 35us/step - loss: 0.6155 - acc: 0.6598 - val_loss: 0.6303 - val_acc: 0.6357\n",
      "Epoch 5/100000\n",
      "307646/307646 [==============================] - 11s 35us/step - loss: 0.6078 - acc: 0.6678 - val_loss: 0.6395 - val_acc: 0.6296\n"
     ]
    }
   ],
   "source": [
    "mlp = Sequential()\n",
    "mlp.add(Dense(30, activation='sigmoid', input_dim=input_dim)) # Camada de entrada\n",
    "mlp.add(Dense(1, activation='tanh')) # Camada de saída\n",
    "mlp.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = mlp.fit(X_train_res, y_train_res, batch_size=64, epochs=100000, \n",
    "        callbacks=[EarlyStopping(patience=3)], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perda Média de Validação: 0.63\n"
     ]
    }
   ],
   "source": [
    "print(\"Perda Média de Validação: %.2f\"%(np.mean(history.history['val_loss'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Notamos que a função adadelta gerou uma menor perda.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 11s 35us/step - loss: 0.6358 - acc: 0.6384 - val_loss: 0.6713 - val_acc: 0.5815\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 10s 32us/step - loss: 0.6178 - acc: 0.6575 - val_loss: 0.6412 - val_acc: 0.6187\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 10s 32us/step - loss: 0.6059 - acc: 0.6694 - val_loss: 0.6468 - val_acc: 0.6198\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 10s 32us/step - loss: 0.5956 - acc: 0.6778 - val_loss: 0.6698 - val_acc: 0.6004\n",
      "Epoch 5/100000\n",
      "307646/307646 [==============================] - 10s 32us/step - loss: 0.5877 - acc: 0.6817 - val_loss: 0.6123 - val_acc: 0.6598\n",
      "Epoch 6/100000\n",
      "307646/307646 [==============================] - 10s 32us/step - loss: 0.5819 - acc: 0.6846 - val_loss: 0.6098 - val_acc: 0.6694\n",
      "Epoch 7/100000\n",
      "307646/307646 [==============================] - 10s 32us/step - loss: 0.5778 - acc: 0.6872 - val_loss: 0.6111 - val_acc: 0.6600\n",
      "Epoch 8/100000\n",
      "307646/307646 [==============================] - 10s 32us/step - loss: 0.5743 - acc: 0.6897 - val_loss: 0.6533 - val_acc: 0.6155\n",
      "Epoch 9/100000\n",
      "307646/307646 [==============================] - 11s 36us/step - loss: 0.5716 - acc: 0.6918 - val_loss: 0.6307 - val_acc: 0.6426\n"
     ]
    }
   ],
   "source": [
    "mlp = Sequential()\n",
    "mlp.add(Dense(30, activation='relu', input_dim=input_dim)) # Camada de entrada\n",
    "mlp.add(Dense(1, activation='sigmoid')) # Camada de saída\n",
    "mlp.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = mlp.fit(X_train_res, y_train_res, batch_size=64, epochs=100000, \n",
    "        callbacks=[EarlyStopping(patience=3)], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perda Média de Validação: 0.64\n"
     ]
    }
   ],
   "source": [
    "print(\"Perda Média de Validação: %.2f\"%(np.mean(history.history['val_loss'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>No fim não houve muita mudança e os valores otimizados para cada teste gerou um valor próximo de todos os outros testes (0.64)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Camadas Escondidas</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_nodes = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 13s 42us/step - loss: 0.6385 - acc: 0.6350 - val_loss: 0.6683 - val_acc: 0.5958\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 11s 36us/step - loss: 0.6213 - acc: 0.6532 - val_loss: 0.6388 - val_acc: 0.6216\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 11s 37us/step - loss: 0.6124 - acc: 0.6628 - val_loss: 0.6175 - val_acc: 0.6486\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 12s 40us/step - loss: 0.6053 - acc: 0.6707 - val_loss: 0.6550 - val_acc: 0.6126\n",
      "Epoch 5/100000\n",
      "307646/307646 [==============================] - 11s 36us/step - loss: 0.5968 - acc: 0.6787 - val_loss: 0.6747 - val_acc: 0.5967\n",
      "Epoch 6/100000\n",
      "307646/307646 [==============================] - 12s 39us/step - loss: 0.5884 - acc: 0.6836 - val_loss: 0.6188 - val_acc: 0.6515\n",
      "Para 0 camadas escondidas:\n",
      "\tPerda Média: 0.65\n",
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 14s 44us/step - loss: 0.6350 - acc: 0.6391 - val_loss: 0.6337 - val_acc: 0.6251\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 12s 38us/step - loss: 0.6160 - acc: 0.6599 - val_loss: 0.6481 - val_acc: 0.6147\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 14s 44us/step - loss: 0.6056 - acc: 0.6708 - val_loss: 0.6742 - val_acc: 0.5965\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 12s 38us/step - loss: 0.5956 - acc: 0.6797 - val_loss: 0.6379 - val_acc: 0.6314\n",
      "Para 1 camadas escondidas:\n",
      "\tPerda Média: 0.65\n",
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 13s 43us/step - loss: 0.6339 - acc: 0.6397 - val_loss: 0.6661 - val_acc: 0.5865\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 13s 44us/step - loss: 0.6170 - acc: 0.6592 - val_loss: 0.6239 - val_acc: 0.6499\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 12s 38us/step - loss: 0.6070 - acc: 0.6695 - val_loss: 0.6436 - val_acc: 0.6181\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 14s 46us/step - loss: 0.5973 - acc: 0.6777 - val_loss: 0.6450 - val_acc: 0.6291\n",
      "Epoch 5/100000\n",
      "307646/307646 [==============================] - 13s 42us/step - loss: 0.5885 - acc: 0.6843 - val_loss: 0.6644 - val_acc: 0.6228\n",
      "Para 2 camadas escondidas:\n",
      "\tPerda Média: 0.65\n",
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 15s 50us/step - loss: 0.6355 - acc: 0.6374 - val_loss: 0.6416 - val_acc: 0.6243\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 15s 48us/step - loss: 0.6162 - acc: 0.6600 - val_loss: 0.6291 - val_acc: 0.6384\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 15s 48us/step - loss: 0.6045 - acc: 0.6709 - val_loss: 0.6919 - val_acc: 0.6003\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 14s 44us/step - loss: 0.5948 - acc: 0.6785 - val_loss: 0.6136 - val_acc: 0.6616\n",
      "Epoch 5/100000\n",
      "307646/307646 [==============================] - 14s 46us/step - loss: 0.5843 - acc: 0.6863 - val_loss: 0.6223 - val_acc: 0.6503\n",
      "Epoch 6/100000\n",
      "307646/307646 [==============================] - 13s 42us/step - loss: 0.5693 - acc: 0.6941 - val_loss: 0.6830 - val_acc: 0.6220\n",
      "Epoch 7/100000\n",
      "307646/307646 [==============================] - 13s 44us/step - loss: 0.5559 - acc: 0.7005 - val_loss: 0.6077 - val_acc: 0.6660\n",
      "Epoch 8/100000\n",
      "307646/307646 [==============================] - 13s 42us/step - loss: 0.5487 - acc: 0.7040 - val_loss: 0.6145 - val_acc: 0.6569\n",
      "Epoch 9/100000\n",
      "307646/307646 [==============================] - 13s 42us/step - loss: 0.5441 - acc: 0.7061 - val_loss: 0.6075 - val_acc: 0.6686\n",
      "Epoch 10/100000\n",
      "307646/307646 [==============================] - 13s 43us/step - loss: 0.5423 - acc: 0.7067 - val_loss: 0.6060 - val_acc: 0.6698\n",
      "Epoch 11/100000\n",
      "307646/307646 [==============================] - 13s 43us/step - loss: 0.5401 - acc: 0.7092 - val_loss: 0.6133 - val_acc: 0.6641\n",
      "Epoch 12/100000\n",
      "307646/307646 [==============================] - 12s 40us/step - loss: 0.5382 - acc: 0.7104 - val_loss: 0.6018 - val_acc: 0.6748\n",
      "Epoch 13/100000\n",
      "307646/307646 [==============================] - 12s 38us/step - loss: 0.5367 - acc: 0.7113 - val_loss: 0.6282 - val_acc: 0.6474\n",
      "Epoch 14/100000\n",
      "307646/307646 [==============================] - 12s 39us/step - loss: 0.5355 - acc: 0.7128 - val_loss: 0.6109 - val_acc: 0.6641\n",
      "Epoch 15/100000\n",
      "307646/307646 [==============================] - 12s 39us/step - loss: 0.5343 - acc: 0.7131 - val_loss: 0.6250 - val_acc: 0.6473\n",
      "Para 3 camadas escondidas:\n",
      "\tPerda Média: 0.63\n",
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 14s 44us/step - loss: 0.6371 - acc: 0.6362 - val_loss: 0.6354 - val_acc: 0.6248\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 13s 41us/step - loss: 0.6174 - acc: 0.6588 - val_loss: 0.6339 - val_acc: 0.6322\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 13s 42us/step - loss: 0.6038 - acc: 0.6719 - val_loss: 0.6408 - val_acc: 0.6314\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 13s 43us/step - loss: 0.5897 - acc: 0.6809 - val_loss: 0.6108 - val_acc: 0.6678\n",
      "Epoch 5/100000\n",
      "307646/307646 [==============================] - 12s 40us/step - loss: 0.5784 - acc: 0.6867 - val_loss: 0.6210 - val_acc: 0.6550\n",
      "Epoch 6/100000\n",
      "307646/307646 [==============================] - 12s 39us/step - loss: 0.5727 - acc: 0.6909 - val_loss: 0.6213 - val_acc: 0.6538\n",
      "Epoch 7/100000\n",
      "307646/307646 [==============================] - 13s 41us/step - loss: 0.5684 - acc: 0.6934 - val_loss: 0.6191 - val_acc: 0.6575\n",
      "Para 4 camadas escondidas:\n",
      "\tPerda Média: 0.63\n",
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 14s 46us/step - loss: 0.6362 - acc: 0.6362 - val_loss: 0.6555 - val_acc: 0.6239\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 14s 45us/step - loss: 0.6211 - acc: 0.6547 - val_loss: 0.6191 - val_acc: 0.6483\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 13s 43us/step - loss: 0.6140 - acc: 0.6620 - val_loss: 0.6472 - val_acc: 0.6255\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 13s 43us/step - loss: 0.6059 - acc: 0.6699 - val_loss: 0.6423 - val_acc: 0.6272\n",
      "Epoch 5/100000\n",
      "307646/307646 [==============================] - 13s 42us/step - loss: 0.5958 - acc: 0.6772 - val_loss: 0.6508 - val_acc: 0.6328\n",
      "Para 5 camadas escondidas:\n",
      "\tPerda Média: 0.64\n"
     ]
    }
   ],
   "source": [
    "for hidden_layers in range(6):\n",
    "    mlp = Sequential()\n",
    "    mlp.add(Dense(30, activation='relu', input_dim=input_dim)) # Camada de entrada\n",
    "    for i in range(hidden_layers):\n",
    "        mlp.add(Dense(hidden_nodes, activation='relu')) # Camada de entrada\n",
    "    mlp.add(Dense(1, activation='sigmoid')) # Camada de saída\n",
    "    mlp.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = mlp.fit(X_train_res, y_train_res, batch_size=64, epochs=100000, \n",
    "            callbacks=[EarlyStopping(patience=3)], validation_data=(X_val, y_val))\n",
    "    print('Para %d camadas escondidas:\\n\\tPerda Média: %.2f'%(hidden_layers, np.mean(history.history['val_loss'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>O erro médio se manteve entre os mesmos valores [0.63, 0.65], porém notamos um acerto maior no conjunto de validação quando utilizamos 3 camadas escondidas.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Batch Size</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 9s 29us/step - loss: 0.6366 - acc: 0.6351 - val_loss: 0.6661 - val_acc: 0.5969\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 8s 26us/step - loss: 0.6177 - acc: 0.6572 - val_loss: 0.6440 - val_acc: 0.6269\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 8s 26us/step - loss: 0.6076 - acc: 0.6674 - val_loss: 0.6452 - val_acc: 0.6223\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 8s 26us/step - loss: 0.5995 - acc: 0.6756 - val_loss: 0.6459 - val_acc: 0.6319\n",
      "Epoch 5/100000\n",
      "307646/307646 [==============================] - 8s 26us/step - loss: 0.5907 - acc: 0.6833 - val_loss: 0.6634 - val_acc: 0.6143\n",
      "Perda Média: 0.65\n"
     ]
    }
   ],
   "source": [
    "opt_hidden_layer = 3\n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(30, activation='relu', input_dim=input_dim)) # Camada de entrada\n",
    "for i in range(opt_hidden_layer):\n",
    "    mlp.add(Dense(hidden_nodes, activation='relu')) # Camada de entrada\n",
    "mlp.add(Dense(1, activation='sigmoid')) # Camada de saída\n",
    "mlp.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = mlp.fit(X_train_res, y_train_res, batch_size=128, epochs=100000, \n",
    "        callbacks=[EarlyStopping(patience=3)], validation_data=(X_val, y_val))\n",
    "print('Perda Média: %.2f'%(np.mean(history.history['val_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307646 samples, validate on 26077 samples\n",
      "Epoch 1/100000\n",
      "307646/307646 [==============================] - 17s 54us/step - loss: 0.6336 - acc: 0.6397 - val_loss: 0.6490 - val_acc: 0.6185\n",
      "Epoch 2/100000\n",
      "307646/307646 [==============================] - 13s 44us/step - loss: 0.6129 - acc: 0.6631 - val_loss: 0.6194 - val_acc: 0.6510\n",
      "Epoch 3/100000\n",
      "307646/307646 [==============================] - 13s 44us/step - loss: 0.5956 - acc: 0.6755 - val_loss: 0.6396 - val_acc: 0.6322\n",
      "Epoch 4/100000\n",
      "307646/307646 [==============================] - 14s 45us/step - loss: 0.5794 - acc: 0.6849 - val_loss: 0.6212 - val_acc: 0.6556\n",
      "Epoch 5/100000\n",
      "307646/307646 [==============================] - 14s 44us/step - loss: 0.5684 - acc: 0.6916 - val_loss: 0.6170 - val_acc: 0.6552\n",
      "Epoch 6/100000\n",
      "307646/307646 [==============================] - 14s 46us/step - loss: 0.5604 - acc: 0.6960 - val_loss: 0.6316 - val_acc: 0.6452\n",
      "Epoch 7/100000\n",
      "307646/307646 [==============================] - 14s 44us/step - loss: 0.5559 - acc: 0.6983 - val_loss: 0.6113 - val_acc: 0.6617\n",
      "Epoch 8/100000\n",
      "307646/307646 [==============================] - 14s 45us/step - loss: 0.5535 - acc: 0.7003 - val_loss: 0.6153 - val_acc: 0.6605\n",
      "Epoch 9/100000\n",
      "307646/307646 [==============================] - 13s 44us/step - loss: 0.5513 - acc: 0.7013 - val_loss: 0.6112 - val_acc: 0.6663\n",
      "Epoch 10/100000\n",
      "307646/307646 [==============================] - 14s 45us/step - loss: 0.5501 - acc: 0.7022 - val_loss: 0.6108 - val_acc: 0.6670\n",
      "Epoch 11/100000\n",
      "307646/307646 [==============================] - 14s 44us/step - loss: 0.5493 - acc: 0.7036 - val_loss: 0.6060 - val_acc: 0.6676\n",
      "Epoch 12/100000\n",
      "307646/307646 [==============================] - 14s 46us/step - loss: 0.5484 - acc: 0.7045 - val_loss: 0.6216 - val_acc: 0.6518\n",
      "Epoch 13/100000\n",
      "307646/307646 [==============================] - 14s 45us/step - loss: 0.5484 - acc: 0.7047 - val_loss: 0.6196 - val_acc: 0.6571\n",
      "Epoch 14/100000\n",
      "307646/307646 [==============================] - 14s 45us/step - loss: 0.5480 - acc: 0.7058 - val_loss: 0.6317 - val_acc: 0.6498\n",
      "Perda Média: 0.62\n"
     ]
    }
   ],
   "source": [
    "opt_hidden_layer = 3\n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(30, activation='relu', input_dim=input_dim)) # Camada de entrada\n",
    "for i in range(opt_hidden_layer):\n",
    "    mlp.add(Dense(hidden_nodes, activation='relu')) # Camada de entrada\n",
    "mlp.add(Dense(1, activation='sigmoid')) # Camada de saída\n",
    "mlp.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = mlp.fit(X_train_res, y_train_res, batch_size=32, epochs=100000, \n",
    "        callbacks=[EarlyStopping(patience=3)], validation_data=(X_val, y_val))\n",
    "print('Perda Média: %.2f'%(np.mean(history.history['val_loss'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Para o tamanho do batch = 32 obtivemos a menor perda.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluation = mlp.evaluate(X_test, y_test, batch_size=32)\n",
    "print(\"Conjunto de Teste:\\n\\tPerda: %.3f\\n\\tAcurácia: %.3f\"%(test_evaluation[0],test_evaluation[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict_classes(X_test)\n",
    "y_pred_proba = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método auxiliar para imprimir todas as métricas para um classificador\n",
    "def generateMetrics(y_true, y_pred, y_pred_proba = None):\n",
    "    print(\"Acurácia: %.5f\"%(accuracy_score(y_true=y_true, y_pred=y_pred)))\n",
    "    print(\"Recall: %.5f\"%(recall_score(y_true=y_true, y_pred=y_pred)))\n",
    "    print(\"Precisão: %.5f\"%(precision_score(y_true=y_true, y_pred=y_pred)))\n",
    "    print(\"F1-Score: %.5f\"%(f1_score(y_true=y_true, y_pred=y_pred)))\n",
    "    if not y_pred_proba is None:\n",
    "        print(\"Área Sobre a Curva ROC: %.5f\"%(roc_auc_score(y_true=y_true, y_score=y_pred_proba)))\n",
    "        print(\"Precisão Média sobre as Probabilidades:%.5f\"%(average_precision_score(y_true=y_true, y_score=y_pred_proba)))\n",
    "        print(\"Matriz de Confusão:\\n\")\n",
    "        print(pd.DataFrame(confusion_matrix(y_true=y_true, y_pred=y_pred), \n",
    "                           columns=['P', 'N'], \n",
    "                           index=['P', 'N']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas Geradas para o MLP:\n",
      "Acurácia: 0.65165\n",
      "Recall: 0.71463\n",
      "Precisão: 0.74385\n",
      "F1-Score: 0.72895\n",
      "Área Sobre a Curva ROC: 0.68076\n",
      "Precisão Média sobre as Probabilidades:0.79633\n",
      "Matriz de Confusão:\n",
      "\n",
      "       P      N\n",
      "P  23535  20717\n",
      "N  24023  60160\n"
     ]
    }
   ],
   "source": [
    "print('Métricas Geradas para o MLP:')\n",
    "generateMetrics(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distr(y_true:pd.DataFrame, y_pred_proba:np.array):\n",
    "    ac_distr_0 = np.zeros(101)\n",
    "    ac_distr_1 = np.zeros(101)\n",
    "    count_classes = y_true['IND_BOM_1_1'].value_counts()\n",
    "    for i in range(1, 101):\n",
    "        lim = i/100.0\n",
    "        count_classes = y_true[y_pred_proba <= lim]['IND_BOM_1_1'].value_counts()\n",
    "        ac_distr_0[i] += count_classes[0]\n",
    "        ac_distr_1[i] += count_classes[1]\n",
    "    return (ac_distr_0/count_classes[0], ac_distr_1/count_classes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr_0, distr_1 = calc_distr(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.17821782178217827, pvalue=0.07148265768062076)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_2samp(distr_0, distr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6813878353811542"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true=y_test, y_score=y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
